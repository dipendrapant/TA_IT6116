{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d23a81-3943-4487-9cc5-7d7a7c2ad741",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f79dd3-1891-4b9f-a0a4-c2e06665c038",
   "metadata": {},
   "source": [
    "\n",
    "To check out what is machine learning __[machine learning](https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained)__ \n",
    "For __[supervised learning](https://www.guru99.com/supervised-machine-learning.html)__ or __[supervised learning, kaggle tutorial](https://www.kaggle.com/code/marcovasquez/top-machine-learning-algorithms-beginner)__ read this   \n",
    "for __[unsupervised learning]( https://www.guru99.com/unsupervised-machine-learning.html)__ or __[unsupervised learning, kaggle tutorial](https://www.kaggle.com/code/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering )__\n",
    "\n",
    "This lab contains 3 major part \n",
    "1. Feature Selection \n",
    "2. Model Selection, their Implementation and their optimization\n",
    "3. Text Classification with Naive bayes multinomial models\n",
    "\n",
    "In this lab, you will implement the concept of supervised machine learning. Using the provided dataset you will implement algorithms like\n",
    "1. __[Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)__ or (https://www.projectpro.io/article/scikit-learn-linear-regression-example/539)\n",
    "2.  __[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)__ or (https://www.kaggle.com/code/prashant111/random-forest-classifier-tutorial)\n",
    "3. __[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__ or (https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial)\n",
    "4.  __[Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)__ or (https://www.kaggle.com/code/shailx/text-classification-with-naive-bayes-classifier/notebook)   \n",
    "\n",
    "and the process involved when using machine learning\n",
    "\n",
    "Libraries used \n",
    "1. Pandas and Numpy (From earlier lab for Data analysis)\n",
    "2. __[Sklearn 1.2.2](https://scikit-learn.org/stable/)__ (For Machine Learning Implementation)\n",
    "3. __[NLTK](https://www.nltk.org/)__ (For text processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bcc25-3892-4bfa-ba4e-2a34be0f58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraries needed for the lab\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tutorial6 import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "# Display the topmost data in the DATA_4 Dataframe without index which we are going to use for this lab. \n",
    "# So have a careful look of what the Dataframe contains and looks like\n",
    "DATA_4.head(4).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e95337-c452-4c43-bfc3-afb7c81d7a4d",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844f812-46f9-459c-ad5f-e9141f4153f3",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "**Involves identifying the most important features or selecting the features for training the model and creating new ones that can be used as inputs for \n",
    "the machine learning model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6bb1c-75fb-4bb1-8ce5-df8b6ce70a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection Demonstration\n",
    "test_data = [[7,'normal',25,4,'labrador'],[12,'high',35,5,'german shephard']]\n",
    "test_df = pd.DataFrame(test_data,columns=['age','diet','weight','height','breed'])\n",
    "test_df.head().style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece14b71-48c2-4a44-89a6-e756709e22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7498de4-724a-41b8-b920-6e3130056844",
   "metadata": {},
   "source": [
    "### Task 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23679f-2826-4151-967a-b4f597273cbd",
   "metadata": {},
   "source": [
    "Create a DataFrame named `days_only_df` only conisting the 3 features or columns `'age_first_contact_days'`, \n",
    "`'age_last_contact_days'`, `'age_dead_days'` using `loc` in the dataframe `DATA_4`. \n",
    "\n",
    "\n",
    "Tips: `DATA_4.loc[rows,columns]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d954ce4-204a-4672-baa5-d721db7888ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "days_only_df = __________________\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q1_1_check(days_only_df)\n",
    "\n",
    "# View Output Dataframe\n",
    "days_only_df.head(4).style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e52be-8c44-4ed8-8dc7-35af99b4239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q1_1_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec88ec-01ac-4f9d-b2f4-9fdd89a11335",
   "metadata": {},
   "source": [
    "### Task 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2ccd5-66d3-4278-8a5e-2b1d24ce9fca",
   "metadata": {},
   "source": [
    "Create a DataFrame named `days_only_df` only conisting the 3 features or columns `'age_first_contact_days'`, `'age_last_contact_days'`, `'age_dead_days'` from the dataframe `DATA_4` using double square brackets `[[_______]]`?\n",
    "\n",
    "\n",
    "Tips: `DATA_4[[column names]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acaff2-a1e9-43ae-ba24-ee8011a95d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "days_only_df = __________________\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q1_2_check(days_only_df)\n",
    "\n",
    "# View Output Dataframe\n",
    "days_only_df.head(4).style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202050d0-9f6c-430f-9d95-b16e961092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q1_2_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480aefee-257e-4f65-9ae0-4617d4d91461",
   "metadata": {},
   "source": [
    "## Task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273a6ca-ac5d-4208-99ac-af3de11d6f56",
   "metadata": {},
   "source": [
    "Create a two new DataFrames from `DATA_4`, the first one named `independent_variable` consisting columns or features `'age_first_contact_days'`, `'age_last_contact_days'` and second one named `dependent_variable` consisting column or label`'age_dead_year'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d1012-0b7b-4afa-8031-911b1217fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Select the columns and assign them as a DataFrame named independent_variable \n",
    "independent_variable = __________________\n",
    "\n",
    "# Select the column and assign it to a DataFrame named dependent_variable\n",
    "dependent_variable = __________________\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q2_check(independent_variable,dependent_variable)\n",
    "\n",
    "# View Output Dataframe\n",
    "display(independent_variable.head(4).style.hide(axis=\"index\"))\n",
    "display(dependent_variable.head(4).style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa9dd8-c65a-4e86-9aec-7ab6d81192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q2_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c9b6f-9f98-4651-88ef-c225ece89f0d",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "---------------------------------------------------------------------------------\n",
    "Train Test Split is spliting the data frame into two categories. \n",
    "1. Train Dataset: Used to fit(train) the machine learning model.\n",
    "2. Test Dataset: Used to evaluate(test) the fit machine learning model.\n",
    "\n",
    "To know more check out: \n",
    "    __[machinelearningmastery](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/)__\n",
    "    \n",
    "---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043c1a8-d21d-472a-8938-fbd009ce8aa3",
   "metadata": {},
   "source": [
    "Split the above `independent_variable` and `dependent_variable` or the dataset into train & test using `Sklearn` `train_test_split()` method\n",
    ", the 80% of data is allocated for training and 20 % for testing. where \n",
    "\n",
    " - `independent_variable` train data is named as `X_train` and test data as `X_test`\n",
    " - `dependent_variable` train data is named as `y_train` and test data as `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3af90-51db-4f9d-a1dd-13ff3f1241e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "X_train, X_test, y_train, y_test = __________________\n",
    "print(f'Size of X_train:{X_train.shape},X_test:{X_test.shape},y_train:{y_train.shape},y_test:{y_test.shape}')\n",
    "\n",
    "# Check your answer\n",
    "q3_check(str(X_train.shape), str(X_test.shape), str(y_train.shape), str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f429d6-764a-4897-b058-97173817f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q3_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b351f-9f51-460b-bb84-d2dd9c71563b",
   "metadata": {},
   "source": [
    "### Task 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a77504-62da-4b57-9116-abce263f121c",
   "metadata": {},
   "source": [
    "Complete the code inside the `'_______'` of code_to_fit_model variable .\n",
    "The code should be for trainning the model named as `model` using `fit()` passing the `X_train` & `y_train` data as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8fdd9-a0ce-4afc-96e3-f2c208a76edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "code_to_fit_model = '__________________'\n",
    "print(code_to_fit_model)\n",
    "\n",
    "# Check your answer\n",
    "q4_1_check(code_to_fit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b51c46-ece0-455e-9e56-08fc5103a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q4_1_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b08c2-3e4c-49fa-95c6-1e385a39a2e2",
   "metadata": {},
   "source": [
    "### Task 4.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14ab4d-627d-4606-b501-7c096f849177",
   "metadata": {},
   "source": [
    "Apply one hot encoding for trasforming the `gender` column into `gender_male`,`gender_female` and once transformation is done after one hot encoding, drop the original gender column. And analysze the\n",
    "output to understand how gender is represented as \t `gender_male`,`gender_female` in the dataframe `DATA_4_2` below.\n",
    "\n",
    "Tips: Here you simply need to read the lines of code and place `OneHotEncoder()` and `drop()` respectively in the appropriate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8b8f4-948b-4513-a350-88c028188eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Your code goes here.\n",
    "\n",
    "# Create a deep copy of the Dataframe DATA_4\n",
    "DATA_4_2 = DATA_4.copy(deep=True)\n",
    "\n",
    "# Create a new DataFrame with only the \"gender\" column\n",
    "gender_df = DATA_4_2[['gender']]\n",
    "\n",
    "# Use OneHotEncoder to perform one-hot encoding on the \"gender\" column\n",
    "encoder = __________________(sparse_output=False)\n",
    "gender_encoded = encoder.fit_transform(gender_df)\n",
    "\n",
    "# Convert the encoded array back to a DataFrame and append it to the original DataFrame\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded.astype(\"int32\"), columns=['gender_male', 'gender_female'])\n",
    "DATA_4_2 = pd.concat([DATA_4_2, gender_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original \"gender\" column from the DataFrame\n",
    "DATA_4_2.__________________('gender', axis=1, inplace=True)\n",
    "\n",
    "# Check your answer\n",
    "q4_2_check(DATA_4_2)\n",
    "\n",
    "# View Output Dataframe\n",
    "DATA_4_2.head(4).style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b486c3-b784-4155-ab12-bfd6768ec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q4_2_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f14faa-2cab-43a5-809e-040dc5b63f7d",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa565105-31cc-455f-816f-aaf25644a8f6",
   "metadata": {},
   "source": [
    "## Model Selection: \n",
    "**Applying supervised machine learning algotihums using Sklearn libarary** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da57a7-bb51-4b54-b248-472953846ac3",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9990a6a-9ab3-429d-b8a4-5146b0adc7c9",
   "metadata": {},
   "source": [
    "Use `Linear Regression` from `Sklearn` to predict the `dependent_variable` which is `'age_diagnosis_year'` from `DATA_4`  \n",
    "based on `independent_variable` which are `'age_first_contact_days'`, `'age_last_contact_days'`, `'age_dead_days'`,`'age_first_contact_year'`, `'age_last_contact_year'`, `'age_dead_year'`. Use 80% of the data for training and 20% for testing\n",
    "\n",
    "Tips: Apply `LinearRegression()` and then apply `fit()` to fit the model using `X_train`, `y_train` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafbf21-b730-4a4b-915b-94e448867e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Select the columns of interest (ie., independent variables) and assign them as a DataFrame to independent_variable \n",
    "independent_variable = DATA_4[['age_first_contact_days', 'age_last_contact_days', 'age_dead_days',\n",
    "        'age_first_contact_year', 'age_last_contact_year', 'age_dead_year']]\n",
    "\n",
    "\n",
    "# Select the column to predict (ie., dependent variable) and assign it to a DataFrame to dependent_variable\n",
    "dependent_variable = DATA_4[['age_diagnosis_year']]\n",
    "\n",
    "\n",
    "# Split the data into training and test sets into 80-20 ratio\n",
    "X_train, X_test, y_train, y_test = __________________(__________________, __________________, test_size=__________________)\n",
    "\n",
    "# Train or fit() the linear regression model on the training set\n",
    "model = __________________\n",
    "model.__________________(X_train, y_train)\n",
    "\n",
    "\n",
    "# This line of code is for checking the performance of the model for checking the correct output i.e, Check the R square value of the model and display it\n",
    "score = model.score(X_test, y_test)\n",
    "print('R^2 score:', score)\n",
    "\n",
    "\n",
    "############################\n",
    "# Check your answer\n",
    "q5_check(str(score)[:3]) \n",
    "# Predict the dependent variable using the independent variables in the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Create a scatter plot of the predicted values against the actual values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Age at Diagnosis')\n",
    "plt.ylabel('Predicted Age at Diagnosis')\n",
    "# Add a line to the scatter plot that shows the predicted values for a range of independent variables\n",
    "x_range = np.arange(y_test['age_diagnosis_year'].min(), y_test['age_diagnosis_year'].max())\n",
    "y_range = x_range\n",
    "plt.plot(x_range, y_range, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339f7c2-7fa9-49fe-800b-979c734e944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q5_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48dd0f6-2fc2-4c8f-87ce-cac7480a9aee",
   "metadata": {},
   "source": [
    "### Task 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dad21-816d-461e-8e5f-8b3cd98ee004",
   "metadata": {},
   "source": [
    "Provide the correct option from `1`,`2`, `3`, `4` for this question. Taking reference of the above Task 5 `model`, What do you think does this line of code will do? \n",
    "`prediction = model.predict([[_____________]])` does ?\n",
    "\n",
    " 1. Predict `age_diagnosis_year` based on provided input independent variable values\n",
    " 2. Predict independent variable values based on `age_diagnosis_year`\n",
    " 3. Stores a dataframe consisisting of all provided values in prediction variables\n",
    " 4. Does Nothing \n",
    " \n",
    " Instruction: Input `1` if you think 1st option is correct answer, Else input `2` if you think 2nd option is correct answer and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff661b5-e7b0-4e87-b1b9-0099600758ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "task6_answer = input('Enter the correct option amoung 1,2,3,4 = ')\n",
    "\n",
    "# Check your answer\n",
    "q6_check(task6_answer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d93e5-2daa-4f96-80ff-def8169f02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q6_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fbb73-bfe0-4be6-b35b-6b004599f9f0",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac7bff-406b-4929-96da-065c5ebc3b44",
   "metadata": {},
   "source": [
    "Using the above (Task 5) Linear Regression model named as `model`, to predict the `age_diagnosis_year` by providing  `age_first_contact_days`, `age_last_contact_days`, `age_dead_days`, `age_first_contact_year`, `age_last_contact_year`, `age_dead_year` values as user inputs. Pass user input as argument to predict method in the same order, as the user input was taken. \n",
    "\n",
    "Tips: Apply `predict()` and then display prediction output which is \"first element of the first element in prediction i.e, prediction[0][0]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799421c2-77cc-41d1-a411-a547c82e5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the prediction using the trained linear regression model\n",
    "\n",
    "# Provide the following input values for the independent variables\n",
    "age_first_contact_days = int(input('Enter age at first contact in days as: 23215 = '))\n",
    "age_last_contact_days = int(input('Enter age at last contact in days as: 23373 = '))\n",
    "age_dead_days = int(input('Enter age at death in days as: 24073 = '))\n",
    "age_first_contact_year = int(input('Enter year of first contact as: 63 = '))\n",
    "age_last_contact_year = int(input('Enter year of last contact as: 63 = '))\n",
    "age_dead_year = int(input('Enter year of death as: 65 = '))\n",
    "\n",
    "# Assign the user input or independent variable values to predict age_diagnosis_year\n",
    "prediction = model.__________________([[age_first_contact_days, age_last_contact_days, age_dead_days, \n",
    "                             age_first_contact_year, age_last_contact_year, age_dead_year]])\n",
    "\n",
    "# print the first element of the first element in prediction\n",
    "print('Linear regression model prediction for age_diagnosis_year is:', __________________[0][0])\n",
    "\n",
    "# Check your answer\n",
    "q7_check(str(prediction[0][0])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68008a-35ad-43ae-be1e-6d4c232d567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q7_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f891e5-3363-49a2-9d7b-15ac887eb63a",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2534bd5-5d75-45a1-99d8-ec4174465e57",
   "metadata": {},
   "source": [
    "Use `Linear Regression` from `Sklearn` to predict the `dependent_variable` which is `age_diagnosis_year` from `DATA_4`  \n",
    "based on `independent_variable` which are `gender`, `age_first_contact_days`, `age_last_contact_days`, `age_dead_days`,`age_first_contact_year`,\n",
    "`age_last_contact_year`,`age_dead_year`, using 80% of the data for training and 20% for testing. Keeping all the `Linear Regression` parameters default or without any parameters\n",
    "\n",
    "Just for Knowledge Only: Here in DATA_4 gender was in categorical form with \"male\" and \"female\" as two category. So we applied Integer Encoding to transform \"male\" as 0 and \"female\" as 1. \n",
    "Also we could have applied and One hot Encoder. To know more check the Task 4.2 above and read the article by \n",
    "__[machinelearningmastery](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)__ \n",
    "\n",
    "\n",
    "Tips: Here you have to apply all the concept learned from the `Task 1` to `Task 7`. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b52a1-37d5-4e11-aeb4-db743342b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Select the columns of interest (ie., independent variables) and assign them as a DataFrame to independent_variable \n",
    "independent_variable = DATA_5[['gender','age_first_contact_days', 'age_last_contact_days', 'age_dead_days', 'age_first_contact_year', 'age_last_contact_year', \n",
    "               'age_dead_year']]\n",
    "\n",
    "# Select the column to predict (ie., dependent variable) and assign it to a DataFrame to dependent_variable\n",
    "dependent_variable = DATA_5[['age_diagnosis_year']]\n",
    "\n",
    "\n",
    "# Split the data into training and test sets into 80-20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variable,dependent_variable,test_size=0.2)\n",
    "\n",
    "# Select the liner regression method and fit it on the training set\n",
    "model_lin = __________________\n",
    "__________________.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# This line of code is for checking the performance of the model for checking the correct output i.e, Check the R square value of the model and display it\n",
    "score = model_lin.score(X_test, y_test)\n",
    "print('R^2 score:', score)\n",
    "\n",
    "\n",
    "# Taking user input for making prediction using the above trained linear regression model\n",
    "# Provide the following input values for the independent variables\n",
    "gender = int(input('Enter gender as 1 = '))\n",
    "age_first_contact_days = int(input('Enter age at first contact in days as 23215 = '))\n",
    "age_last_contact_days = int(input('Enter age at last contact in days as 23373 = '))\n",
    "age_dead_days = int(input('Enter age at death in days as 24073 = '))\n",
    "age_first_contact_year = int(input('Enter year of first contact as 63 = '))\n",
    "age_last_contact_year = int(input('Enter year of last contact as 63 = '))\n",
    "age_dead_year = int(input('Enter year of death as 65 = '))\n",
    "\n",
    "# Assign the user input or independent variable values to predict age_diagnosis_year\n",
    "prediction = __________________.predict([[gender,age_first_contact_days, age_last_contact_days, age_dead_days, age_first_contact_year, \n",
    "                   age_last_contact_year, age_dead_year]])\n",
    "\n",
    "# print the first element of the first element in prediction\n",
    "print('Linear regression model prediction for age_diagnosis_year is:', prediction[0][0])\n",
    "\n",
    "# Check your answer\n",
    "q8_check(str(prediction[0][0])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadccb84-895c-4a31-82e0-4e3211b2e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q8_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f4022-b28e-40bd-9980-94b060fd34ed",
   "metadata": {},
   "source": [
    "### Task 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5845d-0dcc-4b1f-89a7-e5e6a6cca3c2",
   "metadata": {},
   "source": [
    "Brainstrom which above machine learning model (amoung `model_lin`, `model`)  \n",
    "is better for predicting age_diagnosis_year. Write `model_lin` if you think `model_lin` is better, else write `model`.  \n",
    "\n",
    "Tips: See `Task 5` and `Task 8` results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34a387-81a5-4004-b43d-af4591646f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answer \n",
    "better_model_amoung__modelgen_model_for_age_diagnosis_year_prediction = input('Enter your answer here  = ')\n",
    "\n",
    "# Check your answer\n",
    "q9_check(better_model_amoung__modelgen_model_for_age_diagnosis_year_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82fb10-f731-4c4e-8d0f-2f12c868f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q9_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2f7dd-4bac-4682-87e3-248cf20b9486",
   "metadata": {},
   "source": [
    "### Task 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f8aa1-937f-461c-991e-1cad208a4b1c",
   "metadata": {},
   "source": [
    "Use `Random Forest` from `Sklearn` to predict the `dependent_variable` as `age_diagnosis_year` from `DATA_5`  \n",
    "based on `independent_variable` thats contains `gender`, `age_first_contact_days`, `age_last_contact_days`, `age_dead_days`,`age_first_contact_year`,\n",
    "`age_last_contact_year`,`age_dead_year`, using 80% of the data for training and 20% for testing. Keeping all the `Random forest` parameters default or without any parameters\n",
    "\n",
    "Just for Knowledge Only: To understand and know what random forest algorithm is read this article __[builtin](https://builtin.com/data-science/random-forest-algorithm)__  or  __[analyticsvidhya](https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/)__ \n",
    "and how it is implemented with Sklearn library  read this __[scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)__ \n",
    "\n",
    "Note: Complete execution of this may take time (As it involves model trainning using the large dataset), so wait until the complete execution is completed. Thank you for your patience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef524e-1a07-442d-b9b2-ebca29799b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Select the columns of interest (ie., independent variables) and assign them as a DataFrame to independent_variable \n",
    "independent_variable = DATA_5[['gender','age_first_contact_days', 'age_last_contact_days', 'age_dead_days', \n",
    "                               'age_first_contact_year', 'age_last_contact_year', 'age_dead_year']]\n",
    "\n",
    "# Select the column to predict (ie., dependent variable) and assign it to a DataFrame to dependent_variable\n",
    "dependent_variable = DATA_5[['age_diagnosis_year']]\n",
    "\n",
    "\n",
    "# Split the data into training and test sets into 80-20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variable,dependent_variable,test_size=0.2)\n",
    "\n",
    "# Select and fit the Random Forest Classifier model on the training set\n",
    "model_ran = RandomForestClassifier()\n",
    "model_ran.fit(X_train, y_train)\n",
    "\n",
    "DATA_5.info()\n",
    "\n",
    "# This line of code is for checking the performance of the model for checking the correct output i.e, Check the R square value of the model and display it\n",
    "score = model_ran.score(X_test, y_test)\n",
    "print('R^2 score:', X_test)\n",
    "\n",
    "\n",
    "# Taking user input for making prediction using the above trained Random Forest model\n",
    "# Provide the following input values for the independent variables\n",
    "gender = int(input('Enter gender [0 for male, 1 for female] as 1 = '))\n",
    "age_first_contact_days = int(input('Enter age at first contact in days [In dataset max is 35159 and min is 0] as 22222 = '))\n",
    "age_last_contact_days = int(input('Enter age at last contact in days [In dataset max is 36956 and min is 0] as 22222 = '))\n",
    "age_dead_days = int(input('Enter age at death in days [In dataset max is 37692 and min is 0]as 22222 = '))\n",
    "age_first_contact_year = int(input('Enter year of first contact [In dataset max is 96 and min is 0] as 22 = '))\n",
    "age_last_contact_year = int(input('Enter year of last contact [In dataset max is 101 and min is 0] as 22 = '))\n",
    "age_dead_year = int(input('Enter year of death [In dataset max is 103 and min is 0] as 22 = '))\n",
    "\n",
    "# Assign the user input or independent variable values to predict age_diagnosis_year\n",
    "prediction = model_ran.predict([[gender,age_first_contact_days, age_last_contact_days, age_dead_days, age_first_contact_year, \n",
    "                   age_last_contact_year, age_dead_year]])\n",
    "\n",
    "# print the first element in prediction\n",
    "print('Random Forest model prediction for age_diagnosis_year is:', prediction[0])\n",
    "\n",
    "# Check your answer\n",
    "q10_check(gender,age_first_contact_days, age_last_contact_days, age_dead_days, age_first_contact_year, \n",
    "                   age_last_contact_year, age_dead_year,str(prediction[0])[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8c648-bcad-4c17-8439-3654c424a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q10_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e07dda-6bfb-4e88-8c58-980cc70136eb",
   "metadata": {},
   "source": [
    "### Task 11: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03280c45-b41e-4bbb-9da7-04c774c9b422",
   "metadata": {},
   "source": [
    "Use `Logistic Regression` from `Sklearn` to predict the `dependent_variable` thats contains `age_diagnosis_year` from `DATA_4`  \n",
    "based on `independent_variable` thats contains `gender`, `age_first_contact_days`, `age_last_contact_days`, `age_dead_days`, using 80% of the data for training and 20% for testing. Keeping all the `Logistic Regression` parameters default or without any parameters\n",
    "\n",
    "Just for Knowledge Only: To understand and know what random forest algorithm is read this article __[builtin](https://builtin.com/data-science/random-forest-algorithm)__  or  __[analyticsvidhya](https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/)__ \n",
    "and how it is implemented with Sklearn library  read this __[scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)__ \n",
    "\n",
    "Note: Complete execution of this may take time (As it involves model trainning using the large dataset), so wait until the complete execution is completed. Thank you for your patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aa363-80ed-4b79-af72-604461b4ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code goes here.\n",
    "\n",
    "# Select the columns of interest (ie., independent variables) and assign them as a DataFrame to independent_variable \n",
    "independent_variable = DATA_5[['gender','age_first_contact_days', 'age_last_contact_days', 'age_dead_days']]\n",
    "\n",
    "# Select the column to predict (ie., dependent variable) and assign it to a DataFrame to dependent_variable\n",
    "dependent_variable = DATA_5[['age_diagnosis_year']]\n",
    "\n",
    "\n",
    "# Split the data into training and test sets into 80-20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variable, dependent_variable, test_size=0.2)\n",
    "\n",
    "# Train or fit() the logistic regression model on the training set\n",
    "model_logistic = __________________\n",
    "#fit the model_logistic using X_train and y_train data\n",
    "__________________.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Check the R square value of the model and display it\n",
    "score = model_logistic.score(X_test, y_test)\n",
    "print('R^2 score:', score)\n",
    "\n",
    "\n",
    "# Provide the following input values for the independent variables\n",
    "gender = int(input('Enter gender : (0 for male and 1 for female) = '))\n",
    "age_first_contact_days = int(input('Enter age at first contact in days (In dataset max is 35159 and min is 0) = '))\n",
    "age_last_contact_days = int(input('Enter age at last contact in days (In dataset max is 36956 and min is 0) = '))\n",
    "age_dead_days = int(input('Enter age at death in days (In dataset max is 37692 and min is 0) = '))\n",
    "\n",
    "\n",
    "#Predict the output using trained model_log. Based on the provided user input \n",
    "prediction = model_logistic.predict([[gender,age_first_contact_days,age_last_contact_days,age_dead_days]])\n",
    "#print the predicted output\n",
    "print('Logistic Regression model prediction for age_diagnosis_year is:', prediction)\n",
    "\n",
    "# Check your answer\n",
    "q11_check(gender,age_first_contact_days, age_last_contact_days, age_dead_days,str(prediction[0])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc947d6-645e-43d0-9790-7dba4c28e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q11_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5898e1-9564-40d1-a2b6-fdfd4c924159",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f6537-be2d-4873-a7b9-14ad69a8a390",
   "metadata": {},
   "source": [
    "## Model Optimization\n",
    "\n",
    "This cell is for reading only\n",
    "- **Optimize machine learning models performance using techniques such as \n",
    "hyperparameter tuning and cross-validation. The below techniques can be applied for optimization (to improve the performance of the model and \n",
    "avoid overfitting)**\n",
    "\n",
    "1. Feature Selection: You can use techniques such as Recursive Feature Elimination (RFE) or Principal Component Analysis (PCA) to identify the most important features.\n",
    "\n",
    "2. Regularization: Regularization techniques such as Ridge or Lasso can help to avoid overfitting and improve the generalization of the model.\n",
    "\n",
    "3. Hyperparameter tuning: You can tune the hyperparameters of the model such as alpha (in case of regularization), learning rate, and number of iterations to get better performance.\n",
    "\n",
    "4. Cross-validation: Cross-validation can help to evaluate the model's performance on unseen data and avoid overfitting. You can use techniques such as k-fold cross-validation to evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba81c6-eaca-4632-afa6-8b33d57a145b",
   "metadata": {},
   "source": [
    "### Task 12: \n",
    "**Feature selection is selecting the most relevant features for your model. \n",
    "You can use techniques such as Recursive Feature Elimination (RFE) or Principal Component Analysis (PCA) to \n",
    "identify the most important features.**\n",
    "\n",
    "Apply the recursive feature elimination (RFE) on Random Forest Classifier below for identifying the 3 most important or best features to train the  Random Forest Classifier model. \n",
    "Here go through the lines of code and apply `RFE()` method on `RandomForestClassifier()` and `fit()` to display the 3 most important or best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a123b-46fc-4d10-a215-e66f8f75516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your code goes here.\n",
    "\n",
    "independent_variable = DATA_5[['gender','age_first_contact_days', 'age_last_contact_days', 'age_dead_days', 'age_first_contact_year', 'age_last_contact_year', \n",
    "               'age_dead_year']]\n",
    "dependent_variable = DATA_5[['age_diagnosis_year']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variable, dependent_variable, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "rfe_method = __________________(\n",
    "    __________________(\n",
    "    #n_estimators parameter sets the number of trees in the random forest to be 10 and random_state sets the random seed to be used by the algorithm for reproducibility.\n",
    "    n_estimators=10, \n",
    "    # random_state sets the random seed to be used by the algorithm for reproducibility.\n",
    "    random_state=10),\n",
    "    #it will select the top 3 features.\n",
    "    n_features_to_select=3,\n",
    "    #determines the number of features to remove at each iteration of the RFE algorithm. In this case, it will remove 2 features at each iteration.\n",
    "    step=2,\n",
    ")\n",
    "#fit the RFE\n",
    "rfe_method.__________________(X_train, y_train)\n",
    "\n",
    "# Displays the selected top 4 features\n",
    "print(X_train.columns[(rfe_method.get_support())].tolist())\n",
    "\n",
    "# Check your answer\n",
    "q12_check(X_train.columns[(rfe_method.get_support())].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4c2ca-ae9e-45cd-8afe-f77d32647db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q12_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038e2e8-d75e-4c7f-8486-e5e537a83b93",
   "metadata": {},
   "source": [
    "### Task 13: \n",
    "**Hyperparameter tuning: You can tune the hyperparameters of the model such as fit_intercept, copy_X, n_jobs , learning rate, number of iterations, and many others to get better performance.**\n",
    "\n",
    "To know \n",
    "1. fit_intercept=True\n",
    "https://stackoverflow.com/questions/46779605/in-the-linearregression-method-in-sklearn-what-exactly-is-the-fit-intercept-par\n",
    "\n",
    "2. 'copy_X': True meaning read this:\n",
    "https://stackoverflow.com/questions/53711167/what-is-the-meaning-of-copy-x-in-sklearn-linear-models\n",
    "\n",
    "3. 'n_jobs': None\n",
    "The n_jobs parameter accepts two values:\n",
    "    1. n_jobs = None: If n_jobs is set to None, the algorithm will use only one CPU core. This is the default setting.\n",
    "    2. n_jobs = -1: If n_jobs is set to -1, the algorithm will use all available CPU cores.\n",
    "    3. Setting n_jobs to a value greater than 1 can speed up the computation time for large datasets. This is because linear regression involves matrix operations that can be parallelized and distributed across multiple CPU cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9ed22-7af1-4ae8-ac24-f7eff140db51",
   "metadata": {},
   "source": [
    "Apply the `linear regression` algorithm from and fit `model_lin` using `X_train`, `y_train data`. \n",
    "Then perform a grid search cross-validation on a linear regression model `model_lin` with hyperparameters specified by the `param_grid` parameter. And finally `fit` the GridSearchCV object to the training data `X_train` and `y_train`\n",
    "\n",
    "Tips: Use `GridSearchCV()` to apply grid search cross validation and `fit()` to fit the `GridSearchCV` object to the training data `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72aa68-6b80-4008-b2c2-041a2768ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "independent_variable = DATA_5[['gender','age_first_contact_days', 'age_last_contact_days', 'age_dead_days', 'age_first_contact_year', 'age_last_contact_year', \n",
    "               'age_dead_year']]\n",
    "dependent_variable = DATA_5[['age_diagnosis_year']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variable, dependent_variable, test_size=0.2)\n",
    "\n",
    "param_grid = { 'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [None, -1]}\n",
    "\n",
    "#fit the linear regression model\n",
    "model_lin = LinearRegression()\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "#Apply grid search cross validation\n",
    "grid = GridSearchCV(model_lin, param_grid=param_grid, \n",
    "                    #goal of the grid search is to find the hyperparameters that optimize the scoring metric, which is set to 'r2' (i.e., the coefficient of determination)\n",
    "                    scoring='r2', \n",
    "                    # cv=5 (i.e., a 5-fold cross-validation)\n",
    "                    cv=5)\n",
    "# fit the GridSearchCV object to the training data X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "\n",
    "# This line of code is for checking the performance of the model for checking the correct output i.e, Check the R square value of the model and display it\n",
    "score = model_lin.score(X_test, y_test)\n",
    "print('R^2 score:', score)\n",
    "\n",
    "# Check your answer\n",
    "q13_check(\"{'copy_X': True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587f7af-a2b7-42dd-bce1-2261e97112bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q13_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a9458-80ff-4a8e-b2ef-bb1e67bbc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6ab0a-da46-4915-a556-b06933863d2d",
   "metadata": {},
   "source": [
    "## Text Classification based on diagnosis codes (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081824d-ed8e-42d5-9436-fbbca24e0ca5",
   "metadata": {},
   "source": [
    "### Task 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0bd112-540a-4376-994a-898ed05873be",
   "metadata": {},
   "source": [
    "Read and analyze the code below. And select the correct option to explain what the code below does on the newly copied `DATA_20`. Follow the sequential order\n",
    "1. Lowercase conversion --> Word Tokenization --> Stopword removal --> Stemming --> Joinnin the processed and stemmed words as a string \n",
    "2. Uppercase conversion --> Word Tokenization --> Stopword removal --> Stemming --> Joinnin the processed and stemmed words as a string \n",
    "3. Dataset Copy --> Stopword removal --> Word Tokenization --> Stemming --> Joinnin the processed and stemmed words as a string \n",
    "3. Dataset Copy --> Word Tokenization --> Stemming --> Stopword removal --> Joinnin the processed and stemmed words as a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeeb803-5e37-4a8a-a3c3-93bc23bfc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "DATA_20 = DATA_66.copy(deep=True)\n",
    "DATA_20['diagnosis_text'] = DATA_20['diagnosis_text'].apply(lambda x: x.lower())\n",
    "DATA_20['diagnosis_text'] = DATA_20['diagnosis_text'].apply(lambda x: word_tokenize(x))\n",
    "stop_words = set(stopwords.words('norwegian'))\n",
    "DATA_20['diagnosis_text'] = DATA_20['diagnosis_text'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "stemmer = SnowballStemmer('norwegian')\n",
    "DATA_20['diagnosis_text'] = DATA_20['diagnosis_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "DATA_20['diagnosis_text'] = DATA_20['diagnosis_text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Provide the following input values for the independent variables\n",
    "answer = str(input('Enter your choice [1,2,3,4] = '))\n",
    "\n",
    "# Check your answer\n",
    "q14_check(answer)\n",
    "\n",
    "#view the Dataframe before preprocessing\n",
    "print(\"DataFrame Before Preprocessing\")\n",
    "display(DATA_66.tail(2).style.hide(axis='index'))\n",
    "#view the preprocessed Dataframe\n",
    "print(\"DataFrame After Preprocessing\")\n",
    "display(DATA_20.tail(2).style.hide(axis='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db077a-6de9-43f4-970c-481db662e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q14_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0a865-9327-4033-9e69-b7b7d36fb69d",
   "metadata": {},
   "source": [
    "### Task 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac6e5c-a6cd-47ba-b8d7-760e16d94df6",
   "metadata": {},
   "source": [
    "Apply `multinomial naive bayes` classifier to train the classifier on the vectorized text data and disply the obtained `accuracy` of the trained `classifier` on test data `X_test, y_test`.\n",
    "\n",
    "Tips: Use `MultinomialNB()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c411f8-292b-4bad-9d65-2421098d56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Select the features and output label\n",
    "X = DATA_20['diagnosis_text']\n",
    "y = DATA_20['diagnosis_code']\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = __________________\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = classifier.score(__________________)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "acc = str(accuracy)\n",
    "\n",
    "# Check your answer\n",
    "q15_check(acc[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16ee34-bf30-4788-8e46-c645812f0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q15_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc6f03-fa07-45d1-94e0-2a03b390bb43",
   "metadata": {},
   "source": [
    "### Task 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233b56a-e956-4bca-8ab3-bc689d04772d",
   "metadata": {},
   "source": [
    "Read and analyze the code below and try to understand what is happening. Apply the `necessary missing method` for `predicting` the output based on provided user input `diagnosis_text` vectororized into `X_user`. Then provide `Uspesifisert aplastisk anemi` as input to the trained model `classifier` to check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0915cca-bcaf-42c9-98df-54f37a6a556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Take user input for diagnosis_text\n",
    "diagnosis_text = input('Enter the diagnosis text (in Norwegian) i.e, Uspesifisert aplastisk anemi : ')\n",
    "\n",
    "# Vectorize the user input\n",
    "X_user = vectorizer.transform([__________________])\n",
    "\n",
    "# Predict the diagnosis_code on classifier model\n",
    "diagnosis_code = __________________.predict(X_user)\n",
    "\n",
    "# Print the predicted diagnosis_code\n",
    "print('The predicted diagnosis code for is:', diagnosis_code[0])\n",
    "\n",
    "# Check your answer\n",
    "q16_check(diagnosis_code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794f768-07b9-4d27-a0b9-4820481094ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q16_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a6cf3-7528-4416-b9c4-314b310ab2e8",
   "metadata": {},
   "source": [
    "### Task 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25679f88-673f-4e7e-b73f-7005706ae34b",
   "metadata": {},
   "source": [
    "Read and analyze the code below and try to understand what is happening. Apply the `necessary missing method` to vectorize the user input. Then provide `ikke-reumatisk aortainsuffisi` as input to the trained model `classifier` to check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ce16c-257b-455b-b6d7-fff14b321927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "# Take user input for diagnosis_text\n",
    "diagnosis_text = input('Enter the diagnosis text (in Norwegian): ikke-reumatisk aortainsuffisi ')\n",
    "\n",
    "# Vectorize the user input\n",
    "X_user = __________________.__________________([diagnosis_text])\n",
    "\n",
    "# Predict the diagnosis_code\n",
    "diagnosis_code = classifier.predict(X_user)\n",
    "\n",
    "# Print the predicted diagnosis_code\n",
    "print('The predicted diagnosis code', diagnosis_code[0])\n",
    "\n",
    "# Check your answer\n",
    "q17_check(diagnosis_code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8ac48-bc76-45ad-9c43-bc26d6821d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q17_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f760aa4-fd37-44bf-a8bd-e8eedd737a06",
   "metadata": {},
   "source": [
    "### Task 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccfe504-db1a-401b-976a-949235dc95f7",
   "metadata": {},
   "source": [
    "Read and analyze the code below carefully. Then apply pricipal component analysis `PCA()` on the `DATA_88` to reduce the dimensionality from 9 features `'gender', 'age_first_contact_days', 'age_last_contact_days', 'age_diagnosis_days', 'age_dead_days', 'age_diagnosis_year', 'age_first_contact_year', 'age_last_contact_year', 'age_dead_year'` into 2 features `PC1` and `PC2`. \n",
    "\n",
    "Note: Principal component analysis is used to reduce the dimensionality of large datsetdataset with many columns or features into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be44ca9-b9b6-46d6-a644-002ee74c0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "DATA_88 = DATA_66.copy(deep=True)\n",
    "#select column for one hot encoding\n",
    "onehotencode_feature = ['gender']\n",
    "# Select the columns to use for PCA\n",
    "features = ['age_first_contact_days', 'age_last_contact_days', 'age_diagnosis_days', 'age_dead_days', 'age_diagnosis_year', 'age_first_contact_year', 'age_last_contact_year', 'age_dead_year']\n",
    "\n",
    "\n",
    "# # Create a PCA object with 2 principal components\n",
    "# pca = __________________(n_components=__________________)\n",
    "\n",
    "# # Fit the PCA model on the standardized features\n",
    "# pca.fit(DATA_88[features])\n",
    "\n",
    "# # Transform the standardized features into 2 principal components\n",
    "# transformed_data = pca.transform(DATA_88[features])\n",
    "\n",
    "# # Create a new dataset with PC1 and PC2 as features\n",
    "# new_data = pd.DataFrame({'PC1': transformed_data[:, 0], 'PC2': transformed_data[:, 1]})\n",
    "\n",
    "# # Check your answer\n",
    "# q18_check(new_data)\n",
    "\n",
    "#new_DATA_88.head(4).style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ff0ad-e45c-4ace-91af-c6b220932677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view answer\n",
    "q18_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de8bb7-6fb7-408b-83b7-650536611aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_66.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6352296-116c-4425-9a3f-acd1f75f7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_feature = scaler.fit_transform(DATA_88[features])\n",
    "\n",
    "# One hot encoding of the categorical data\n",
    "encoder = OneHotEncoder()\n",
    "categorical_vars_encoded = encoder.fit_transform(DATA_88[onehotencode_feature])\n",
    "\n",
    "#new dataframe composed after concatination\n",
    "new_DATA_88 = pd.concat([pd.DataFrame(categorical_vars_encoded.toarray()),pd.DataFrame(scaled_feature)],axis=1)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "principal_component = pca.fit_transform(new_DATA_88)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the scree plot\n",
    "plt.plot(range(1,11), pca.explained_variance_ratio_, marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualize the principal components\n",
    "pc_df = pd.DataFrame(data = principal_component, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10'])\n",
    "sns.scatterplot(x='PC2', y='PC10', data=pc_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677dcd5-f6f6-4264-9ba4-63ba0535ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here.\n",
    "\n",
    "DATA_88 = DATA_66.copy(deep=True)\n",
    "# Select the columns to use for PCA\n",
    "features = ['age_first_contact_days', 'age_last_contact_days', 'age_diagnosis_days', 'age_dead_days', 'age_diagnosis_year', 'age_first_contact_year', 'age_last_contact_year', 'age_dead_year']\n",
    "\n",
    "#view original data\n",
    "print(\"Original Dataset\")\n",
    "print(\"+++++++++++++++++\")\n",
    "display(DATA_88[features].head(4).style.hide(axis=\"index\"))\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "DATA_88[features] = scaler.fit_transform(DATA_88[features])\n",
    "\n",
    "#View Standarized scaled features\n",
    "print(\"Scaled Features\")\n",
    "print(\"+++++++++++++++++\")\n",
    "display(DATA_88[features].head(4).style.hide(axis=\"index\"))\n",
    "\n",
    "# Create a PCA object with 2 principal components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the PCA model on the standardized features & Transform the standardized features into 2 principal components\n",
    "transformed_data = pca.fit_transform(DATA_88[features])\n",
    "\n",
    "\n",
    "# Create a new dataset with PC1 and PC2 as features\n",
    "new_data = pd.DataFrame({'PC1': transformed_data[:, 0], 'PC2': transformed_data[:, 1]})\n",
    "\n",
    "#View Standarized scaled features\n",
    "print(\"Contribution of features in principal component anaysis\")\n",
    "print(\"+++++++++++++++++\")\n",
    "print(abs(pca.components_ ))\n",
    "\n",
    "# Check your answer\n",
    "q18_check(new_data)\n",
    "\n",
    "#Final principal components\n",
    "print(\"Scaled Features\")\n",
    "print(\"+++++++++++++++++\")\n",
    "display(new_data.head(4).style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890b39d-e0b9-4970-9f4d-b2d2a1825f91",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helsedata_lab",
   "language": "python",
   "name": "helsedata_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
